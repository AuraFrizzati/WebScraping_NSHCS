{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOH9kSax1TKznsWfy8LchN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AuraFrizzati/WebScraping_NSHCS/blob/main/NHSCS_ClinInformatics_WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code to web scrape the Clinical Informatics Curriculum from the NHSCS website**"
      ],
      "metadata": {
        "id": "xQyKZFKEkRcT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zEyBqwRkHUs",
        "outputId": "62828546-db90-4848-f466-cfb4e00315a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipping\n"
          ]
        }
      ],
      "source": [
        "# skip the cells from running\n",
        "%%script echo skipping\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# skip the cells from running\n",
        "%%script echo skipping\n",
        "%pip install requests\n",
        "%pip install html5lib\n",
        "%pip install bs4\n",
        "%pip install pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKCY3rcykuMP",
        "outputId": "b5219988-fe19-42f3-d99a-89ca15509ccd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install xlsxwriter\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import xlsxwriter\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "K-BLj2ick3Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15428a33-bc9d-44d2-86e7-e3c2be822478"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom-made function for filling dictionaries"
      ],
      "metadata": {
        "id": "xxptf_rxJoBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_dictionary(soup_find_name, soup_find_attr1, soup_find_attr2, tag, \n",
        "                    extra_level = False, extra_level_tag = None, extra_level_number = None):\n",
        "  string = ''\n",
        "  if (extra_level == False):\n",
        "    for item in soup.find(soup_find_name, attrs= {soup_find_attr1 : soup_find_attr2}).find_all(tag):\n",
        "      string = string + item.text + \" | \"\n",
        "  if (extra_level == True):\n",
        "    for item in soup.find(soup_find_name, attrs= {soup_find_attr1 : soup_find_attr2}).find_all(extra_level_tag)[extra_level_number].find_all(tag):\n",
        "      string = string + item.text + \" | \"\n",
        "  \n",
        "  return(string[:-2])"
      ],
      "metadata": {
        "id": "mes_1PfEb5JW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract links for Competencies' web pages"
      ],
      "metadata": {
        "id": "0r4JQYLGAmVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Select Clinical Informatics curriculum main page\n",
        "URL = \"https://curriculumlibrary.nshcs.org.uk/stp/specialty/SBI1-3-22/\"\n",
        "r = requests.get(URL)\n",
        "soup = BeautifulSoup(r.content, 'html5lib') ## specify the HTML content and the parser\n",
        "\n",
        "## extract Modules links\n",
        "links = []\n",
        "for section in soup.find_all('table',attrs= {'class' : 'nhsuk-table-responsive'}):\n",
        "  for link in section.find_all('a'):\n",
        "    links.append(link['href'])\n",
        "\n",
        "links = ['https://curriculumlibrary.nshcs.org.uk' + link for link in links]"
      ],
      "metadata": {
        "id": "Ia9IgtWnynuy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZIwkkj42t3S",
        "outputId": "cb067db8-1863-4225-9852-91e305ef17a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://curriculumlibrary.nshcs.org.uk/stp/module/S-C1',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-C2',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-C3',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-C4',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-HI-R1',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-HI-R2',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-BG-R1',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-CSC-R1',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-HI-S1',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-HI-S2',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-HI-S3',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-HI-S4',\n",
              " 'https://curriculumlibrary.nshcs.org.uk/stp/module/S-HI-S5']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Excel spreadsheet for the curriculum"
      ],
      "metadata": {
        "id": "PiCuviZgpsZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open Excel workbook on Google Cloud\n",
        "%cd /content/drive/MyDrive/web scraping/output/\n",
        "writer = pd.ExcelWriter('ClinicalInformatics_curriculum2022.xlsx',engine='xlsxwriter')   \n",
        "workbook=writer.book\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FHXnHUW2pfP",
        "outputId": "7b8c77f0-e08e-4789-f038-31251feaaaaf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/web scraping/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_worsheets = []\n",
        "for link in links:\n",
        "  r = requests.get(link)\n",
        "  soup = BeautifulSoup(r.content, 'html5lib') ## specify the HTML content and the parser\n",
        "\n",
        "  ## [1] Extract Module Details table\n",
        "  mod_details = {}\n",
        "\n",
        "  # extract subsection with Module Summary\n",
        "  for i in range(len(soup.find_all('dt',attrs = {'class':'nhsuk-summary-list__key'}))):\n",
        "    mod_details[soup.find_all('dt',attrs = {'class':'nhsuk-summary-list__key'})[i].text.strip()] = soup.find_all('dd',attrs = {'class':'nhsuk-summary-list__value'})[i].text.strip()\n",
        "  # extract subsection with Module Aim\n",
        "  sub_aim = soup.find('div', attrs= {'class' : 'subsection', 'id':'aim'})\n",
        "  mod_details['Aim'] = sub_aim.text.strip()\n",
        "  # add link to online module\n",
        "  mod_details['Link'] = link\n",
        "  # transform list into df\n",
        "  df_mod_details = pd.DataFrame(mod_details.items())\n",
        "  remove = 'Copy text                        \\n                        \\n                            Aim of this module\\n                            '\n",
        "  df_mod_details[1] = df_mod_details[1].str.replace(remove, '')\n",
        "\n",
        "  # [2] Extract Learning Outcomes table\n",
        "  df_LO = pd.read_html(str(soup.find('div', attrs={'id':'action-wb-learning-outcomes'}).find('table')))[0]\n",
        "\n",
        "  # [3] extract Assessment table \n",
        "  Assessments_dict = {}\n",
        "  Assessments_dict['Assessments'] = fill_dictionary('div','id','work-based-assessments','p')\n",
        "  df_Assessments = pd.DataFrame(Assessments_dict.items())\n",
        "  if soup.find('div', attrs= {'id' : 'work-based-assessments'}).ul is not None:\n",
        "    Assessments_dict['DOPS'] = fill_dictionary('div','id','work-based-assessments','li', \n",
        "                                              extra_level = True, extra_level_tag = 'ul', extra_level_number = 1)\n",
        "    Assessments_dict['OCEs'] = fill_dictionary('div','id','work-based-assessments','li',\n",
        "    extra_level = True, extra_level_tag = 'ul', extra_level_number = 2)\n",
        "    df_Assessments = pd.DataFrame(Assessments_dict.items())\n",
        "    if soup.find('div', attrs= {'id' : 'action-activities'}) is not None:\n",
        "      Assessments_dict['Clinical activities'] = fill_dictionary('div','id','action-activities','li')\n",
        "      df_Assessments = pd.DataFrame(Assessments_dict.items())\n",
        "\n",
        "  # write Module Summary to Excel\n",
        "  title_worksheet = mod_details['Module code']+\"_summary\"\n",
        "  title_worsheets.append(title_worksheet)\n",
        "  worksheet=workbook.add_worksheet(title_worksheet)\n",
        "  writer.sheets[title_worksheet] = worksheet\n",
        "  df_mod_details.to_excel(writer,sheet_name=title_worksheet, header = False, index = False,\n",
        "                          startrow=0 , startcol=0)   \n",
        "  df_LO.to_excel(writer,sheet_name=title_worksheet, index = False,\n",
        "                startrow=df_mod_details.shape[0]+3, startcol=0) \n",
        "  \n",
        "  df_Assessments.to_excel(writer,sheet_name=title_worksheet, header = False, index = False,\n",
        "                startrow=df_mod_details.shape[0]+df_LO.shape[0]+6, startcol=0)\n",
        "  \n",
        "  # Extract Competencies table\n",
        "  df_competencies = pd.read_html(str(soup.find('table', attrs={'class':'nhsuk-table-responsive','id':'table-competencies'})))[0] ## read HTML table in pandas\n",
        "  df_competencies['Learning outcome'] = df_competencies['Learning outcome'].str.replace('Learning outcome', '')\n",
        "  df_competencies['#'] = mod_details['Module code'] + df_competencies['#'].str.replace('# ', '.') + \":\"\n",
        "  df_competencies['Competency'] = df_competencies['#'] + df_competencies['Competency'].str.replace('Competency', '')\n",
        "  df_competencies = df_competencies.drop('#', axis=1)\n",
        "  df_competencies\n",
        "\n",
        "  Views_URLs = [] \n",
        "  for i in range(len(df_competencies.index)):\n",
        "    U = link.replace(\"module\",\"competency\")+\"/\"+str((i+1))\n",
        "    Views_URLs.append(U)\n",
        "  \n",
        "  Views_list = []\n",
        "  for URL in Views_URLs:\n",
        "    r = requests.get(URL)\n",
        "    soup = BeautifulSoup(r.content, 'html5lib')\n",
        "    considerations_list = soup.find('div',attrs={'id':'action-considerations'}).find_all('li')\n",
        "    considerations_string = ''\n",
        "    for item in considerations_list:\n",
        "      considerations_string = considerations_string + item.text + ', '\n",
        "    considerations_string = considerations_string[:-2]\n",
        "    Views_list.append(considerations_string)\n",
        "    time.sleep(random.randint(1,4))\n",
        "  \n",
        "  df_competencies['Action'] = Views_list\n",
        "\n",
        "  # write Module Competencies to Excel\n",
        "  title_worksheet = mod_details['Module code']+\"_competencies\"\n",
        "  title_worsheets.append(title_worksheet)\n",
        "  worksheet=workbook.add_worksheet(title_worksheet)\n",
        "  writer.sheets[title_worksheet] = worksheet\n",
        "  df_competencies.to_excel(writer,sheet_name=title_worksheet, index = False,\n",
        "                          startrow=0 , startcol=0)   \n",
        "    \n",
        "  time.sleep(random.randint(1,4))"
      ],
      "metadata": {
        "id": "W-17weYjommr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## add first worksheet with internal links to the rest of the workbook\n",
        "\n",
        "# create the internal link worksheet\n",
        "title_worksheet = \"index\"\n",
        "worksheet=workbook.add_worksheet(title_worksheet)\n",
        "\n",
        "# create the links\n",
        "i = 0\n",
        "for item in title_worsheets:\n",
        "  i = i+1\n",
        "  worksheet.write_url('A'+str(i),  'internal:'+item+'!A1:B2', string=item)\n",
        "  #worksheet.write_string('B'+str(i), 'Your text here')\n",
        "\n",
        "# Move last spreadsheet (index) as first\n",
        "workbook.worksheets_objs.insert(0, workbook.worksheets_objs.pop())"
      ],
      "metadata": {
        "id": "3wHk-64WFeHi"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Close Excel workbook\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "700mV1Pa2Ir1"
      },
      "execution_count": 94,
      "outputs": []
    }
  ]
}